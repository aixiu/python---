# Python爬虫

## 1.任务介绍

- 需求分析

爬取豆瓣电影Top250的基本信息，包括电影的名称，豆瓣评分，评价数，电影概况，电影链接等。

<https://movie.douban.com/top250>

## 2.爬虫初识

- 什么是爬虫
  - 网络爬虫,是- -种按照一定规则，自动抓取互联网信息的程序或者脚本。由于互联网数据的多样性和资源的有限性,根据用户需求定向抓取相关网页并分析已成为如今主流的爬取策略。
- 爬虫可以做什么
  - 你可以爬取妹子的图片,爬取自己想看的视频等等,只要你能通过浏览器访问的数据都可以通过爬虫获取。
- 爬虫的本质是什么
  - 模拟浏览器打开网页,获取网页中我们想要的那部分数据。

## 3.基本流程

- 准备工作
  - 通过浏览器查看分析目标网页 ,学习编程基础规范。
- 获取数据
  - 通过HTTP库向目标站点发起请求,请求可以包含额外的header等信息,如果服务器能正常响应,会得到一-个Response ,便是所要获取的页面内容。
- 解析内容
  - 得到的内容可能是HTML、json等格式,可以用页面解析库、正则表达式等进行解析。
- 保存数据
  - 保存形式多样,可以存为文本,也可以保存到数据库,或者保存特定格式的文件。

### 3.1准备工作

- URL分析
  - 页面包括250条电影数据，分10页，每页25条
  - 每页的URL不同之处：最后的数据 = （页数-1）*25

### 3.2获取数据

- python一般使用urllib库获取面页

- 获取页面数据

  - 对每一个页面，获取面面内容

  - 定义一个获取页面函数，传入一个url参数，表示网址，如：<https://movie.douban.com/top250?start=0>

  - *urllib.request*生成请求，*urllib.urlopen*发送请求获取响应，*read*获取页面内容

  - 在访问页面时经常会出现错误，为了程序正常运行，加入异常捕获 *try...except...*语句

#### 补充：urllib模块

- 最最基本的请求

- 这是python内置的一个http请求库，不需要额外的安装。只需要关注请求的链接，参数，提供了强大的解析。

  - urllib.request 请求模块
  - urllib.error 异常处理模块
  - urllib.parse 解析模块

- 用法讲解

  - 简单的一个get请求

  - ```python
      import urllib.request
      reponse = urllib.request.urlopen('http://baidu.com')
      print(reponse.read().decode('utf-8'))
      ```

### 3.3解析内容

- 解析页面内容
  - 使用*BeautifulSoup*定位特定的村签位置
  - 使用正则表达式找到具体的内容

### 3.4保存数据

- Excel表存储
  - 利用python库*xlwt*将抽取的数据*datalist*写入Excel表格
